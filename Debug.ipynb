{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ed9176",
   "metadata": {},
   "source": [
    "## Generate news Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5030f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.llm_prompts import *\n",
    "update_news_articles(prod_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63dbaac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from dbb.models import Users, Lessons, UserAnswers , UseCases, NewsArticle # Adjust based on your actual models\n",
    "import json\n",
    "\n",
    "# Connect to the production database\n",
    "prod_engine = create_engine(os.environ['DATABASE_URI'])\n",
    "Session = sessionmaker(bind=prod_engine)\n",
    "prod_session = Session()\n",
    "\n",
    "# Function to copy data from production to test database\n",
    "def copy_data_from_prod_to_test():\n",
    "    # Copy Users\n",
    "    prod_users = prod_session.query(Users).all()\n",
    "    for user in prod_users:\n",
    "        db.session.add(Users(id=user.id, username=user.username, email=user.email,\n",
    "                            hashed_password=user.hashed_password, use_case_difficulty=1,\n",
    "                            score=user.score if user.score else 0, is_admin=user.is_admin, lesson_id=user.lesson_id if user.lesson_id else 1))\n",
    "\n",
    "    # Copy lessons\n",
    "    prod_lessons = prod_session.query(Lessons).all()\n",
    "    for lesson in prod_lessons:\n",
    "        db.session.add(Lessons(id=lesson.id, title=lesson.title))\n",
    "\n",
    "    # Copy user answers\n",
    "    prod_user_answers = prod_session.query(UserAnswers).all()\n",
    "    for user_answer in prod_user_answers:\n",
    "        db.session.add(UserAnswers(id=user_answer.id, user_id=user_answer.user_id,\n",
    "                       use_case_id=user_answer.use_case_id, question_id=user_answer.question_id,\n",
    "                       option_id=user_answer.option_id, is_correct=user_answer.is_correct, created_at=user_answer.created_at,\n",
    "                       lesson_id=user_answer.lesson_id\n",
    "        ))\n",
    "\n",
    "    # Copy use cases\n",
    "    prod_use_cases = prod_session.query(UseCases).all()\n",
    "    for use_case in prod_use_cases:\n",
    "        db.session.add(UseCases(id=use_case.id, description=use_case.description,\n",
    "                       type=use_case.type,\n",
    "                        lesson_id=use_case.lesson_id,\n",
    "                       created_by_user=use_case.created_by_user, risk_factors=json.dumps(use_case.risk_factors)\n",
    "                       , difficulty_id=use_case.difficulty_id, news_article=use_case.news_article\n",
    "        ))\n",
    "\n",
    "    db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da85d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import markdown\n",
    "from flask import Flask\n",
    "from flask import current_app as app\n",
    "from flask import jsonify, redirect, render_template, request, session, url_for\n",
    "from flask_login import (LoginManager, UserMixin, current_user, login_required,\n",
    "                         login_user, logout_user)\n",
    "\n",
    "from app import db, create_app\n",
    "from dbb.models import (DifficultyLevel, Lessons, Options, Questions, UseCases,\n",
    "                        UserAnswers, UserLessonInteraction, Users)\n",
    "from config import TestingConfig, ProductionConfig\n",
    "\n",
    "# app = create_app('TestingConfig')\n",
    "# app_context = app.app_context()\n",
    "# app_context.push()\n",
    "# db.create_all()\n",
    "\n",
    "# # Populate the test database\n",
    "# copy_data_from_prod_to_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_use_case(current_use_case_id, user_id):\n",
    "    \"\"\"\n",
    "    Finds a use case similar to the current one based on shared risk factors.\n",
    "\n",
    "    This function searches for a use case that shares risk factors with the current use case but has not yet been successfully completed by the user. This can help in recommending similar scenarios for further training or assessment.\n",
    "\n",
    "    Args:\n",
    "        current_use_case_id (int): The ID of the current use case.\n",
    "        user_id (int): The ID of the user for whom similar use cases are being searched.\n",
    "\n",
    "    Returns:\n",
    "        UseCases | None: Returns a similar UseCase object if found, otherwise None.\n",
    "    \"\"\"\n",
    "    current_use_case = UseCases.query.get(current_use_case_id)\n",
    "    if not current_use_case:\n",
    "        return None\n",
    "\n",
    "    current_risk_factors = current_use_case.risk_factors\n",
    "\n",
    "    # Query to find a similar use case based on risk factors\n",
    "    similar_use_case = UseCases.query.filter(\n",
    "        UseCases.id != current_use_case_id,\n",
    "        UseCases.risk_factors.contains(current_risk_factors),\n",
    "        ~UseCases.id.in_(\n",
    "            db.session.query(UserAnswers.use_case_id)\n",
    "            .filter(UserAnswers.user_id == user_id, UserAnswers.is_correct)\n",
    "            .distinct()\n",
    "        ),\n",
    "    ).first()\n",
    "\n",
    "    return similar_use_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fa48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_use_case_id = 1\n",
    "current_use_case = UseCases.query.get(current_use_case_id)\n",
    "current_risk_factors = current_use_case.risk_factors\n",
    "current_risk_factors\n",
    "\n",
    "\n",
    "use_1  = json.loads(current_risk_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b869a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_10 = json.loads(current_risk_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6952e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_use_cases = UseCases.query.filter(\n",
    "    UseCases.id != current_use_case_id,\n",
    "    ~UseCases.id.in_(\n",
    "        db.session.query(UserAnswers.use_case_id)\n",
    "        .filter(UserAnswers.user_id == 6, UserAnswers.is_correct)\n",
    "        .distinct()\n",
    "    ),\n",
    ").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_contains(json_obj, query, threshold=0.75):\n",
    "    \"\"\"Check if json_obj contains at least the threshold percentage of key-value pairs in query.\"\"\"\n",
    "    # Flatten the JSON objects for easier comparison\n",
    "    def flatten_json(y):\n",
    "        out = {}\n",
    "        def flatten(x, name=''):\n",
    "            if type(x) is dict:\n",
    "                for a in x:\n",
    "                    flatten(x[a], name + a + '.')\n",
    "            else:\n",
    "                out[name[:-1]] = x\n",
    "        flatten(y)\n",
    "        return out\n",
    "\n",
    "    flat_json_obj = flatten_json(json_obj)\n",
    "    flat_query = flatten_json(query)\n",
    "\n",
    "    total_keys = len(flat_query)\n",
    "    matching_keys = sum(1 for key in flat_query if key in flat_json_obj and flat_json_obj[key] == flat_query[key])\n",
    "\n",
    "    similarity = matching_keys / total_keys if total_keys > 0 else 0\n",
    "    print(similarity)\n",
    "\n",
    "    return similarity >= threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_lesson = Lessons.query.filter_by(id=1).first()\n",
    "\n",
    "use_cases = UseCases.query.filter_by(lesson_id=next_lesson.id).all()\n",
    "\n",
    "lesson_data = {\n",
    "    \"id\": next_lesson.id,\n",
    "    \"title\": next_lesson.title,\n",
    "    \"use_cases\": [\n",
    "        {\n",
    "            \"id\": use_case.id,\n",
    "            \"description\": use_case.description,\n",
    "            # Include other relevant use case data\n",
    "        }\n",
    "        for use_case in use_cases\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d56f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3126d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.session.remove()\n",
    "db.drop_all()\n",
    "app_context.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import markdown\n",
    "from flask import Flask\n",
    "from flask import current_app as app\n",
    "from flask import jsonify, redirect, render_template, request, session, url_for\n",
    "from flask_login import (LoginManager, UserMixin, current_user, login_required,\n",
    "                         login_user, logout_user)\n",
    "\n",
    "from app import db, create_app\n",
    "from dbb.models import (DifficultyLevel, Lessons, Options, Questions, UseCases,\n",
    "                        UserAnswers, UserLessonInteraction, Users)\n",
    "from config import DevelopmentConfig\n",
    "\n",
    "app = create_app(DevelopmentConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c055a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "UseCases.query.filter_by(lesson_id=lesson_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f8603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa7157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e1bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942c737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c85cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae4c33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ec192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52470a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70de674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from xlsx2csv import Xlsx2csv\n",
    "\n",
    "def convert_excel_to_csv(folder_path, output_folder):\n",
    "    # List all Excel files in the folder\n",
    "    excel_files = [file for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "    # Initialize an empty list to store CSV file paths\n",
    "    csv_file_paths = []\n",
    "\n",
    "    # Loop through the list of Excel files\n",
    "    for file in excel_files:\n",
    "        try:\n",
    "            # Construct full file path for the Excel file\n",
    "            excel_file_path = os.path.join(folder_path, file)\n",
    "            # Define the CSV output file path\n",
    "            csv_file_path = os.path.join(output_folder, file.replace('.xlsx', '.csv'))\n",
    "            # Convert Excel file to CSV\n",
    "            Xlsx2csv(excel_file_path, outputencoding=\"utf-8\").convert(csv_file_path)\n",
    "            csv_file_paths.append(csv_file_path)\n",
    "            print(f'Successfully converted {file} to CSV')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to convert {file} to CSV: {e}')\n",
    "\n",
    "    return csv_file_paths\n",
    "\n",
    "def read_and_combine_csv(csv_file_paths):\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through the list of CSV file paths\n",
    "    for csv_file in csv_file_paths:\n",
    "        try:\n",
    "            # Read the CSV file and append the resulting DataFrame to the list\n",
    "            df = pd.read_csv(csv_file, skiprows=1)\n",
    "            dataframes.append(df)\n",
    "            print(f'Successfully read {csv_file}')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to read {csv_file}: {e}')\n",
    "\n",
    "    # Combine all DataFrames into one\n",
    "    if dataframes:\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no files were read\n",
    "\n",
    "# Usage\n",
    "folder_path = '/Users/lucavehbiu/Documents/GitHub/investigamer-cfa/likuidimet'\n",
    "output_folder = '/Users/lucavehbiu/Documents/GitHub/investigamer-cfa/likuidimet_csv'\n",
    "csv_files = convert_excel_to_csv(folder_path, output_folder)\n",
    "combined_dataframe = read_and_combine_csv(csv_files)\n",
    "print(combined_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f365ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df93813",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivered_df = combined_dataframe[combined_dataframe['Status'] == 'Delivered'].copy()\n",
    "\n",
    "print(len(delivered_df))\n",
    "\n",
    "delivered_df_no_dupli = delivered_df.drop_duplicates().copy()\n",
    "\n",
    "print(len(delivered_df_no_dupli))\n",
    "\n",
    "delivered_df_no_dupli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivered_df_no_dupli['vlera_pakos'] = delivered_df_no_dupli['Pay on delivery'].str.replace(' ALL', '').astype(float)\n",
    "delivered_df_no_dupli['transport'] = delivered_df_no_dupli['Transport'].str.replace(' ALL', '').astype(float)\n",
    "\n",
    "delivered_df_no_dupli['Updated'] = pd.to_datetime(delivered_df_no_dupli['Updated'], format='%d %B %Y %H:%M')\n",
    "# Format the datetime objects to 'YYYY-MM'\n",
    "delivered_df_no_dupli['Month_Year'] = delivered_df_no_dupli['Updated'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffddb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delivered_df_no_dupli['transport_287_leke'] = 287.5\n",
    "\n",
    "delivered_df_no_dupli['differenca'] =  delivered_df_no_dupli['transport'] - delivered_df_no_dupli['transport_287_leke']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d900a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "delivered_df_no_dupli['receiver'] =  delivered_df_no_dupli['Receiver'].str.lower()\n",
    "\n",
    "dddelivered_df_no_dupli_no_kosove = delivered_df_no_dupli[~delivered_df_no_dupli['receiver'].str.contains('prishtine|prizren|ferizaj|peje|viti|dragash|prishtina|mitrovice|vushtri|decan|sugareke|suhareke|prizren|shtime|malisheve|rahovec|gjakove|fushe kosove|Ferizaj')].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins\n",
    "bins = [-float('inf'), 0.1, 100, 200, 300, 500, 1000, 2000, float('inf')]\n",
    "# Define the labels for the bins\n",
    "labels = [\n",
    "    '0.0 leke', '0.0 to 100 leke', '101 to 200 leke', '201 to 300 leke',\n",
    "    '301 to 500 leke', '501 to 1000 leke', '1001 to 2000 leke', 'Over 2000 leke'\n",
    "]\n",
    "\n",
    "dddelivered_df_no_dupli_no_kosove['categori_diference'] = pd.cut(dddelivered_df_no_dupli_no_kosove['differenca'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "dddelivered_df_no_dupli_no_kosove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dddelivered_df_no_dupli_no_kosove.groupby(['Month_Year', 'categori_diference']).aggregate({'vlera_pakos' : 'sum',\n",
    "                                                    'transport': 'sum',\n",
    "                                                    'Barcode': 'nunique',\n",
    "                                                    'Receiver':'nunique'\n",
    "                                                       }).reset_index()\n",
    "\n",
    "df['nr_transport_total_muaj'] = df[['Month_Year', 'Barcode']].groupby('Month_Year').transform('sum')['Barcode']\n",
    "df['perqindje_e_porosive'] = df['Barcode'] / df['nr_transport_total_muaj']\n",
    "df.sort_values(['categori_diference', 'Month_Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98092366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dddelivered_df_no_dupli_no_kosove.groupby('Month_Year').aggregate({'vlera_pakos' : 'sum',\n",
    "                                                    'transport': 'sum',\n",
    "                                                    'Barcode': 'nunique',\n",
    "                                                    'Receiver':'nunique'\n",
    "                                                       }).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "df['transport_287_leke'] = 287.5 * df['Barcode']\n",
    "df['differenca_transport_aktual_transport_287_leke'] = df['transport'] - df['transport_287_leke']\n",
    "df.columns = ['muaji', 'vlera_totale_e_pakove', 'vlera_totale_transport', 'nr_barcode', 'nr_receiver', 'vlera_total_transport_288_leke', 'differenca_transport_aktual_transport_287_leke_all']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d12bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[df['categori_diference'] == '0.0 leke']\n",
    "\n",
    "a['perqindje_e_porosive'] = (a['perqindje_e_porosive'].round(3) * 100).astype(str) + '%'\n",
    "\n",
    "a.columns = ['muaji', 'categori_diference', 'vlera_totale_e_pakove', 'vlera_totale_transport', 'nr_barcode', 'nr_receiver', 'nr_barcode_muaji', 'perqindja']\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89726f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('~/Downloads/differenca_transport_per_kategori.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686af440",
   "metadata": {},
   "outputs": [],
   "source": [
    "dddelivered_df_no_dupli_no_kosove.to_excel('~/Downloads/raw_data_me_kategori_diference.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87133ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dddelivered_df_no_dupli_no_kosove"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
